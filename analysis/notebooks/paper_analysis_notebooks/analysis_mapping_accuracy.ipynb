{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da529d61-9843-4416-8ae8-a7857b524457",
   "metadata": {},
   "source": [
    "## Benchmarking mapping accuracy for Tangram2\n",
    "<br>\n",
    "<b>Description</b> : In this notebook we tried to benchmark Tangram2 mapping acuracy with publicly available tools such as Tangram, SpaOTsc and MOSCOT. Here I only show one example of creating 100 spots with one specific patient. The final plot is based on the aggregated result on six patients with varying number of spots<br>\n",
    "<b>Author</b> : Hejin Huang (huang.hejin@gene.com)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ccbb2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/huangh83/miniforge3/envs/tangram2/lib/python3.11/site-packages/louvain/__init__.py:54: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import tangram2 as tg2\n",
    "import tangram as tg\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e628b8b-fcbf-4cf6-8e8a-129e4a73fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = '../../data/tangram2_paper_data/original/scc/'\n",
    "ad_sc = sc.read_h5ad(path + 'scc_new.h5ad')\n",
    "\n",
    "# Select patient and generate cell mix data\n",
    "patient_group = ['P2', 'P4', 'P5', 'P6', 'P9', 'P10']\n",
    "patient = patient_group[0]\n",
    "ad_sc_sample = ad_sc[ad_sc.obs['patient'] == patient]\n",
    "\n",
    "# Define label column\n",
    "label_used = 'level2_celltype_mod' # Assuming this is the intended label based on common usage in similar analyses\n",
    "\n",
    "ad_sp, ad_sc_paired = tg2.evalkit.datagen.cellmix.cellmix.cellmix(ad_sc_sample,\n",
    "              n_spots = 100,\n",
    "              n_cells_per_spot = 10,\n",
    "              n_types_per_spot = 3,\n",
    "              label_col=label_used,\n",
    "              encode_spatial = True,\n",
    "              resample = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044f498a-ab08-41a4-8728-9fe9307628e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get noise levels\n",
    "noise_level = ['no_noise']\n",
    "for key in ad_sp.layers:\n",
    "    noise_level.append(key)\n",
    "\n",
    "# Create ground truth mapping\n",
    "ground_truth = pd.DataFrame(index=ad_sp.obs.index, columns=ad_sc_paired.obs.index).fillna(0)\n",
    "for i in range(len(ad_sp.uns['cellmix_cell_map_mp']['row_self'])):\n",
    "    ground_truth.iloc[ad_sp.uns['cellmix_cell_map_mp']['row_self'][i], ad_sp.uns['cellmix_cell_map_mp']['row_target'][i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ab1c7b-1c92-45de-823d-1d629428245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated data\n",
    "# ad_sp.write_h5ad('/gstore/data/resbioai/tangram2_data/telegraph/res/mapping/100_spot/ad_sp_' + patient + '.h5ad')\n",
    "# ad_sc_paired.write_h5ad('/gstore/data/resbioai/tangram2_data/telegraph/res/mapping/100_spot/ad_sc_' + patient + '.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f10b34-6a1e-4ac9-965b-6e2d48f1ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results dictionaries\n",
    "result_tg2integrate = {}\n",
    "result_tg2cell = {}\n",
    "result_tg1cell = {}\n",
    "result_spaotsc = {}\n",
    "result_moscot = {}\n",
    "result_argmax = {}\n",
    "result_random = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6898637-c12a-4678-a658-9f3dde2f1394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Allocate tensors for mapping.\n",
      "INFO:root:Begin training with 20068 genes and uniform density_prior in clusters mode...\n",
      "INFO:root:Printing scores every 100 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Solid Seed\n",
      "Set Solid Seed\n",
      "Score: 0.927, KL reg: 3.205, Entropy reg: -7.301\n",
      "Score: 0.974, KL reg: 3.178, Entropy reg: -5.796\n",
      "Score: 0.975, KL reg: 3.178, Entropy reg: -5.634\n",
      "Score: 0.975, KL reg: 3.178, Entropy reg: -5.580\n",
      "Score: 0.975, KL reg: 3.178, Entropy reg: -5.555\n",
      "Score: 0.976, KL reg: 3.178, Entropy reg: -5.543\n",
      "Score: 0.976, KL reg: 3.178, Entropy reg: -5.540\n",
      "Score: 0.976, KL reg: 3.178, Entropy reg: -5.532\n",
      "Score: 0.976, KL reg: 3.178, Entropy reg: -5.528\n",
      "Score: 0.976, KL reg: 3.178, Entropy reg: -5.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Renormalizing Single cell data\n",
      "INFO:root:Begin training with 20068 genes and uniform density_prior in cells mode after renormalization\n",
      "INFO:root:Printing scores every 100 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Solid Seed\n",
      "Set Solid Seed\n",
      "Score: 0.936, KL reg: 0.001, Entropy reg: -4132.243\n",
      "Score: 0.997, KL reg: 0.000, Entropy reg: -521.425\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -411.384\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -382.132\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -369.306\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -361.381\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -358.768\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -355.380\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -353.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving results..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.998, KL reg: 0.000, Entropy reg: -351.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:20069 training genes are saved in `uns``training_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:20069 overlapped genes are saved in `uns``overlap_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:uniform based density prior is calculated and saved in `obs``uniform_density` of the spatial Anndata.\n",
      "INFO:root:rna count based density prior is calculated and saved in `obs``rna_count_based_density` of the spatial Anndata.\n",
      "INFO:root:Allocate tensors for mapping.\n",
      "INFO:root:Begin training with 20069 genes and uniform density_prior in cells mode...\n",
      "INFO:root:Printing scores every 100 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.935, KL reg: 0.001, Entropy reg: -4132.243\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -480.119\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -383.662\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -354.646\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -342.843\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -336.384\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -331.145\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -329.991\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -327.414\n",
      "Score: 0.998, KL reg: 0.000, Entropy reg: -326.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving results..\n",
      "INFO:root:20068 training genes are saved in `uns``training_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:20069 overlapped genes are saved in `uns``overlap_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:uniform based density prior is calculated and saved in `obs``uniform_density` of the spatial Anndata.\n",
      "INFO:root:rna count based density prior is calculated and saved in `obs``rna_count_based_density` of the spatial Anndata.\n",
      "INFO:root:Allocate tensors for mapping.\n",
      "INFO:root:Begin training with 20068 genes and uniform density_prior in cells mode...\n",
      "INFO:root:Printing scores every 100 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.478, KL reg: 0.001\n",
      "Score: 0.994, KL reg: 0.002\n",
      "Score: 0.994, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n",
      "Score: 0.995, KL reg: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving results..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Computing pca with `\u001b[33mn_comps\u001b[0m=\u001b[1;36m30\u001b[0m` for `xy` using `adata.X`                                                  \n",
      "\u001b[34mINFO    \u001b[0m Normalizing spatial coordinates of `x`.                                                                   \n",
      "\u001b[34mINFO    \u001b[0m Solving `\u001b[1;36m1\u001b[0m` problems                                                                                      \n",
      "\u001b[34mINFO    \u001b[0m Solving problem OTProblem\u001b[1m[\u001b[0m\u001b[33mstage\u001b[0m=\u001b[32m'prepared'\u001b[0m, \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m1002\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m.                                           \n"
     ]
    }
   ],
   "source": [
    "# Define mapping methods for easier iteration\n",
    "mapping_methods = {\n",
    "    'argmax': {'method': tg2.evalkit.met.map_methods.ArgMaxCorrMap},\n",
    "    'random': {'method': tg2.evalkit.met.map_methods.RandomMap},\n",
    "}\n",
    "\n",
    "for noise in noise_level:\n",
    "    # Prepare AnnData objects for mapping\n",
    "    ad_sc_mapping = ad_sc_paired.copy()\n",
    "    ad_sp_mapping = ad_sp.copy()\n",
    "    if noise != 'no_noise':\n",
    "        ad_sp_mapping.X = ad_sp_mapping.layers[noise]\n",
    "\n",
    "    # Run ArgMaxCorrMap and RandomMap\n",
    "    for method_name, method_dict in mapping_methods.items():\n",
    "        input_dict = tg2.evalkit.met.utils.adatas_to_input(\n",
    "            {'from': ad_sc_mapping, 'to': ad_sp_mapping},\n",
    "            categorical_labels={'from': [label_used]}\n",
    "        )\n",
    "        tg2.evalkit.met.workflows.Workflow({'map': method_dict}).run(input_dict)\n",
    "        if method_name == 'argmax':\n",
    "            result_argmax[noise] = input_dict['T'].copy()\n",
    "        elif method_name == 'random':\n",
    "            result_random[noise] = input_dict['T'].copy()\n",
    "\n",
    "    # Run Tangram2Map (tg2_integrate)\n",
    "    input_dict_tg2integrate = tg2.evalkit.met.utils.adatas_to_input(\n",
    "        {'from': ad_sc_mapping, 'to': ad_sp_mapping},\n",
    "        categorical_labels={'from': [label_used]}\n",
    "    )\n",
    "    tg2.evalkit.met.pp.StandardTangram2.run(input_dict_tg2integrate)\n",
    "    map_res_tg2integrate = tg2.evalkit.met.map_methods.Tangram2Map.run(\n",
    "        input_dict_tg2integrate,\n",
    "        num_epochs=1000,\n",
    "        density_prior='uniform',\n",
    "    )\n",
    "    input_dict_tg2integrate.update(map_res_tg2integrate)\n",
    "    tg2.evalkit.met.pp.StandardScanpy.run(input_dict_tg2integrate, target_objs=['X_from'])\n",
    "    input_dict_tg2integrate['w'].index = input_dict_tg2integrate['w']['cell_type']\n",
    "    result_tg2integrate[noise] = input_dict_tg2integrate['T'].copy()\n",
    "\n",
    "    # Run Tangram2 (tg2.mapping.map_cells_to_space, tg2_cell)\n",
    "    ad_sc_mapping_tg2 = ad_sc_paired.copy()\n",
    "    ad_sp_mapping_tg2 = ad_sp.copy()\n",
    "    if noise != 'no_noise':\n",
    "        ad_sp_mapping_tg2.X = ad_sp_mapping_tg2.layers[noise]\n",
    "    tg2.mapping.pp_adatas(ad_sc_mapping_tg2, ad_sp_mapping_tg2)\n",
    "    ad_map_tg2 = tg2.mapping.map_cells_to_space(\n",
    "        ad_sc_mapping_tg2, ad_sp_mapping_tg2,\n",
    "        mode=\"cells\",\n",
    "        device='cuda:0',\n",
    "        density_prior='uniform',\n",
    "    )\n",
    "    result_tg2cell[noise] = ad_map_tg2.to_df().T\n",
    "\n",
    "    # Run Tangram1 (tan.map_cells_to_space, tg1_cell)\n",
    "    ad_sc_mapping_tg = ad_sc_paired.copy()\n",
    "    ad_sp_mapping_tg = ad_sp.copy()\n",
    "    if noise != 'no_noise':\n",
    "        ad_sp_mapping_tg.X = ad_sp_mapping_tg.layers[noise]\n",
    "    tg.pp_adatas(ad_sc_mapping_tg, ad_sp_mapping_tg)\n",
    "    ad_map_tg = tg.map_cells_to_space(\n",
    "        ad_sc_mapping_tg, ad_sp_mapping_tg,\n",
    "        mode=\"cells\",\n",
    "        device='cuda:0',\n",
    "        density_prior='uniform',\n",
    "    )\n",
    "    result_tg1cell[noise] = ad_map_tg.to_df().T\n",
    "\n",
    "    Run spaOTsc\n",
    "    input_dict_spaotsc = tg2.evalkit.met.utils.adatas_to_input(\n",
    "        {'from': ad_sc_mapping, 'to': ad_sp_mapping},\n",
    "        categorical_labels={'from': [label_used]}\n",
    "    )\n",
    "    wf_spaOT_setup = {\n",
    "        'pp': {'method': tg2.evalkit.met.pp.StandardSpaOTsc},\n",
    "        'map': {'method': tg2.evalkit.met.map.SpaOTscMap, 'params': {'num_epochs': 1000, 'genes': None}},\n",
    "        'pred': {'method': tg2.evalkit.met.pred_methods.MoscotPred},\n",
    "    }\n",
    "    wf_spaOT = tg2.evalkit.met.workflows.Workflow(wf_spaOT_setup)\n",
    "    wf_spaOT.run(input_dict_spaotsc)\n",
    "    result_spaotsc[noise] = input_dict_spaotsc['T']\n",
    "\n",
    "    # Run MOSCOT\n",
    "    input_dict_moscot = tg2.evalkit.met.utils.adatas_to_input(\n",
    "        {'from': ad_sc_mapping, 'to': ad_sp_mapping},\n",
    "        categorical_labels={'from': [label_used]}\n",
    "    )\n",
    "    wf_moscot_setup = {\n",
    "        'pp': {'method': tg2.evalkit.met.pp.StandardMoscot},\n",
    "        'map': {'method': tg2.evalkit.met.map.MoscotMap, 'params': {'num_epochs': 1000, 'genes': None}},\n",
    "        'pred': {'method': tg2.evalkit.met.pred_methods.MoscotPred},\n",
    "    }\n",
    "    wf_moscot = tg2.evalkit.met.workflows.Workflow(wf_moscot_setup)\n",
    "    wf_moscot.run(input_dict_moscot)\n",
    "    result_moscot[noise] = input_dict_moscot['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9192046-6dc9-449c-9801-d21e9aa8fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jaccard Scores\n",
    "result_df = pd.DataFrame(index=noise_level)\n",
    "for noise in noise_level:\n",
    "    result_df.loc[noise, 'tg1_cell'] = jaccard_score((result_tg1cell[noise] == result_tg1cell[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "    result_df.loc[noise, 'tg2_cell'] = jaccard_score((result_tg2cell[noise] == result_tg2cell[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "    result_df.loc[noise, 'tg2_integrate'] = jaccard_score((result_tg2integrate[noise] == result_tg2integrate[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "    result_df.loc[noise, 'moscot'] = jaccard_score((result_moscot[noise] == result_moscot[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "    result_df.loc[noise, 'spaotsc'] = jaccard_score((result_spaotsc[noise] == result_spaotsc[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "    result_df.loc[noise, 'argmax'] = jaccard_score((result_argmax[noise] == result_argmax[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "    result_df.loc[noise, 'random'] = jaccard_score((result_random[noise] == result_random[noise].max()).astype(int).values.flatten(), ground_truth.values.flatten())\n",
    "\n",
    "result_df.to_csv('../../data/tangram2_paper_data/analysis/mapping_benchmark/100_spot/' + patient + '_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f9445-ae0c-43aa-888d-84f73182895d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae40bb-9b37-4493-9193-77da7549f8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ecaee-a228-4670-9956-4a6e593ced0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0863d2-bf3f-42f2-8f4a-c0dead185640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
